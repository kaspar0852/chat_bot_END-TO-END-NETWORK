{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aa1a578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a8e138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_qa.txt','rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "819283ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_qa.txt','rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d41d3201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "821558d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e506b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8522c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we can see 3 main components :\n",
    "#1>the stroy \n",
    "#2>the question\n",
    "#3>the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6737bf61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0]) #the story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0db4257d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1]) #the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a81eaffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n o'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][2]) #answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a40410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eefc618d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46b7c1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "\n",
    "for story,questions,answer in all_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe716f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcfc1af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0f4d195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df0d6d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#while we are constructing our own questions we will be limited to these words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71d127a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1219bbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "474db83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets figure out how long is the longest story and how long is the longest question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "035bb112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Longest Story\n",
    "all_story_lens = [len(data[0]) for data in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c78d0ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_leng = max(all_story_lens) #we will need these later on for padding our sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e79ef8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_story_lens = [len(data[1]) for data in all_data]\n",
    "max_question_leng = max(all_story_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7835ca7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbea93b",
   "metadata": {},
   "source": [
    "# Vectorization \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5f2dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters = [])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "445e8c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': 1,\n",
       " 'apple': 2,\n",
       " '?': 3,\n",
       " 'yes': 4,\n",
       " 'grabbed': 5,\n",
       " 'took': 6,\n",
       " 'up': 7,\n",
       " '.': 8,\n",
       " 'office': 9,\n",
       " 'travelled': 10,\n",
       " 'milk': 11,\n",
       " 'john': 12,\n",
       " 'back': 13,\n",
       " 'bathroom': 14,\n",
       " 'sandra': 15,\n",
       " 'football': 16,\n",
       " 'in': 17,\n",
       " 'to': 18,\n",
       " 'the': 19,\n",
       " 'left': 20,\n",
       " 'went': 21,\n",
       " 'there': 22,\n",
       " 'got': 23,\n",
       " 'moved': 24,\n",
       " 'put': 25,\n",
       " 'journeyed': 26,\n",
       " 'bedroom': 27,\n",
       " 'is': 28,\n",
       " 'garden': 29,\n",
       " 'daniel': 30,\n",
       " 'mary': 31,\n",
       " 'dropped': 32,\n",
       " 'hallway': 33,\n",
       " 'picked': 34,\n",
       " 'down': 35,\n",
       " 'discarded': 36,\n",
       " 'kitchen': 37}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a71d165",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_questions_text = []\n",
    "train_answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3be3abb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for story,questions,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_questions_text.append(questions)   \n",
    "    train_answers.append(answer)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "569ad116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_story_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "511e654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating sequential data format for our stories\n",
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af2b2482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_story_seq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c1480ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we can see that the first word has sequence number 29 which is marry in the orginal stroy. this 29 also matches-\n",
    "#-with tokenizer word index where marry has index 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "565478d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_leng=max_story_leng,max_question_leng=max_question_leng):\n",
    "   \n",
    "    # X = STORIES\n",
    "    X = []\n",
    "    # Xq = QUERY/QUESTION\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWER\n",
    "    Y = []\n",
    "    \n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
    "        # Index 0 is reserved so we're going to use + 1\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        \n",
    "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
    "        #\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "        \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_leng),pad_sequences(Xq, maxlen=max_question_leng), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08c3f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)\n",
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d7e05d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 19, 27,  8],\n",
       "       [ 0,  0,  0, ..., 19, 29,  8],\n",
       "       [ 0,  0,  0, ..., 19, 29,  8],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 19,  2,  8],\n",
       "       [ 0,  0,  0, ..., 19, 29,  8],\n",
       "       [ 0,  0,  0, ...,  2, 22,  8]], dtype=int32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#these are just arrays we have  word index positon along with word index\n",
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f652954c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28, 12, 17, 19, 37,  3],\n",
       "       [28, 12, 17, 19, 37,  3],\n",
       "       [28, 12, 17, 19, 29,  3],\n",
       "       ...,\n",
       "       [28, 31, 17, 19, 27,  3],\n",
       "       [28, 15, 17, 19, 29,  3],\n",
       "       [28, 31, 17, 19, 29,  3]], dtype=int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "819025da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4875357e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0., 503.,   0.,   0., 497.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c5843164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a997e0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b9daebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11cd353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93031df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,Activation,Dense,Permute,Dropout,add,dot,concatenate,LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "31b81c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WE HAVE 2 INPUTS WE HAVE STORIES AND QUESTION THAT THE ENCODER HAS TO UNDERSTAND AND WE HAVE TO LINK THEM TOGETHER-\n",
    "#-TO PROVIDE A LABEL I.E YES OR NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bc810b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WE ARE GOING TO CREATE PLACEHOLDERS USING INPUTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc2bc945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#place holder shape = (max_story_leng,batch_size)\n",
    "input_sequence = Input((max_story_leng,))\n",
    "question = Input((max_question_leng,))\n",
    "#this input take a shape and the shape we are going to pass in are max story length and max question length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9342250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So the above are the place holders ready to receive input later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0c9af549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets create Input Encoders,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c64e3f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a396be47",
   "metadata": {},
   "source": [
    "# Input Encoder M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2e31bc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kaspar/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "input_encoder_m = Sequential()\n",
    "#we will create 2 layers for this the Embedding layer and the dropout layer\n",
    "input_encoder_m.add(Embedding(input_dim = vocab_size,output_dim = 64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "#now what this encoder is going to output is -\n",
    "#-(samples,story_maxlen,embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4887cc",
   "metadata": {},
   "source": [
    "# Input Encoder C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ce522a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoder_c = Sequential()\n",
    "#we will create 2 layers for this the Embedding layer and the dropout layer\n",
    "input_encoder_c.add(Embedding(input_dim = vocab_size,output_dim = max_question_leng))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "\n",
    "##-(samples,story_maxlen,max_question_leng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c39533f",
   "metadata": {},
   "source": [
    "# Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3561a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim = vocab_size,output_dim = 64,input_length = max_question_leng))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "\n",
    "#(samples,query_maxlen,embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70998640",
   "metadata": {},
   "source": [
    "# Now we will encode the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ee6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will want to pass in the input_Sequence,question Inputs() from line 46 to all the encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "24b7e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoded <------- Encoder(Input)\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3094430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = dot([input_encoded_m,question_encoded],axes =(2,2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0940a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = add([match,input_encoded_c])\n",
    "response = Permute((2,1))(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "57c33c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = concatenate([response,question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f2481b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "695eb270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So now we have our answer tensor and we are going to reduce it using RNN here using LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cae9b3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = LSTM(32)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "89c79614",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d252f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer =Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d705904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([input_sequence,question],answer) #and this answer here will link all the encoders here and that is -\n",
    "#-how we link our models with the encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b03248a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'rmsprop',loss = 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "09801a9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_5 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_2[1][0]               \n",
      "                                                                 sequential_5[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_4[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_5[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "37aa646c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kaspar/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/kaspar/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 18:25:09.540112: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2\n",
      "2022-07-21 18:25:09.541460: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.9237 - accuracy: 0.4996 - val_loss: 0.6948 - val_accuracy: 0.5030\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.7017 - accuracy: 0.5011 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6953 - accuracy: 0.5075 - val_loss: 0.6970 - val_accuracy: 0.4970\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6951 - accuracy: 0.4946 - val_loss: 0.6938 - val_accuracy: 0.5030\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.6943 - accuracy: 0.5081 - val_loss: 0.6943 - val_accuracy: 0.5030\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6948 - accuracy: 0.5030 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.6948 - accuracy: 0.4957 - val_loss: 0.6946 - val_accuracy: 0.4970\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.6941 - accuracy: 0.5014 - val_loss: 0.7023 - val_accuracy: 0.4970\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.6949 - accuracy: 0.4980 - val_loss: 0.6932 - val_accuracy: 0.4980\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6943 - accuracy: 0.5051 - val_loss: 0.6936 - val_accuracy: 0.5030\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.6940 - accuracy: 0.4976 - val_loss: 0.6938 - val_accuracy: 0.5030\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.6942 - accuracy: 0.5008 - val_loss: 0.6933 - val_accuracy: 0.4640\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.6917 - accuracy: 0.5196 - val_loss: 0.6882 - val_accuracy: 0.5430\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.6732 - accuracy: 0.5708 - val_loss: 0.6568 - val_accuracy: 0.6120\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.6472 - accuracy: 0.6260 - val_loss: 0.6491 - val_accuracy: 0.6210\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.6308 - accuracy: 0.6495 - val_loss: 0.6369 - val_accuracy: 0.6320\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.6223 - accuracy: 0.6636 - val_loss: 0.6280 - val_accuracy: 0.6450\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.6015 - accuracy: 0.6849 - val_loss: 0.5743 - val_accuracy: 0.7060\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.5534 - accuracy: 0.7306 - val_loss: 0.5363 - val_accuracy: 0.7560\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.5070 - accuracy: 0.7676 - val_loss: 0.4755 - val_accuracy: 0.7890\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.4785 - accuracy: 0.7875 - val_loss: 0.4551 - val_accuracy: 0.7940\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.4470 - accuracy: 0.8051 - val_loss: 0.4410 - val_accuracy: 0.8030\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.4259 - accuracy: 0.8166 - val_loss: 0.4193 - val_accuracy: 0.8140\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.4122 - accuracy: 0.8252 - val_loss: 0.4035 - val_accuracy: 0.8200\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.4012 - accuracy: 0.8314 - val_loss: 0.4042 - val_accuracy: 0.8270\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.3905 - accuracy: 0.8364 - val_loss: 0.4167 - val_accuracy: 0.8380\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.3807 - accuracy: 0.8445 - val_loss: 0.3877 - val_accuracy: 0.8370\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.3743 - accuracy: 0.8437 - val_loss: 0.3846 - val_accuracy: 0.8330\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.3561 - accuracy: 0.8508 - val_loss: 0.3815 - val_accuracy: 0.8330\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.3577 - accuracy: 0.8499 - val_loss: 0.3827 - val_accuracy: 0.8370\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.3525 - accuracy: 0.8521 - val_loss: 0.3736 - val_accuracy: 0.8310\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.3495 - accuracy: 0.8561 - val_loss: 0.3637 - val_accuracy: 0.8360\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.3420 - accuracy: 0.8551 - val_loss: 0.3526 - val_accuracy: 0.8390\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.3340 - accuracy: 0.8628 - val_loss: 0.3601 - val_accuracy: 0.8330\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.3327 - accuracy: 0.8628 - val_loss: 0.3564 - val_accuracy: 0.8400\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.3266 - accuracy: 0.8619 - val_loss: 0.3674 - val_accuracy: 0.8370\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.3245 - accuracy: 0.8629 - val_loss: 0.3754 - val_accuracy: 0.8300\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.3215 - accuracy: 0.8650 - val_loss: 0.3745 - val_accuracy: 0.8380\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.3226 - accuracy: 0.8669 - val_loss: 0.3601 - val_accuracy: 0.8340\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.3179 - accuracy: 0.8694 - val_loss: 0.3570 - val_accuracy: 0.8340\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.3060 - accuracy: 0.8725 - val_loss: 0.3606 - val_accuracy: 0.8280\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.3049 - accuracy: 0.8708 - val_loss: 0.3609 - val_accuracy: 0.8300\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.3053 - accuracy: 0.8714 - val_loss: 0.3843 - val_accuracy: 0.8370\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.3013 - accuracy: 0.8723 - val_loss: 0.3638 - val_accuracy: 0.8400\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.3028 - accuracy: 0.8713 - val_loss: 0.4111 - val_accuracy: 0.8250\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.3029 - accuracy: 0.8713 - val_loss: 0.3584 - val_accuracy: 0.8380\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2975 - accuracy: 0.8745 - val_loss: 0.3768 - val_accuracy: 0.8260\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.3002 - accuracy: 0.8778 - val_loss: 0.3597 - val_accuracy: 0.8360\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2948 - accuracy: 0.8772 - val_loss: 0.4061 - val_accuracy: 0.8190\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2914 - accuracy: 0.8764 - val_loss: 0.3607 - val_accuracy: 0.8290\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2872 - accuracy: 0.8806 - val_loss: 0.3737 - val_accuracy: 0.8290\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2869 - accuracy: 0.8753 - val_loss: 0.3848 - val_accuracy: 0.8260\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2923 - accuracy: 0.8759 - val_loss: 0.3887 - val_accuracy: 0.8300\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2884 - accuracy: 0.8799 - val_loss: 0.4009 - val_accuracy: 0.8240\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2841 - accuracy: 0.8832 - val_loss: 0.4093 - val_accuracy: 0.8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2822 - accuracy: 0.8805 - val_loss: 0.3931 - val_accuracy: 0.8340\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2785 - accuracy: 0.8816 - val_loss: 0.4100 - val_accuracy: 0.8280\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2781 - accuracy: 0.8812 - val_loss: 0.3832 - val_accuracy: 0.8260\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2821 - accuracy: 0.8821 - val_loss: 0.3861 - val_accuracy: 0.8280\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2814 - accuracy: 0.8815 - val_loss: 0.4079 - val_accuracy: 0.8230\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2741 - accuracy: 0.8815 - val_loss: 0.4092 - val_accuracy: 0.8190\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2755 - accuracy: 0.8841 - val_loss: 0.4010 - val_accuracy: 0.8230\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2713 - accuracy: 0.8844 - val_loss: 0.4305 - val_accuracy: 0.8270\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2710 - accuracy: 0.8818 - val_loss: 0.4092 - val_accuracy: 0.8270\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2704 - accuracy: 0.8863 - val_loss: 0.4088 - val_accuracy: 0.8300\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2645 - accuracy: 0.8896 - val_loss: 0.4122 - val_accuracy: 0.8200\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2656 - accuracy: 0.8920 - val_loss: 0.4517 - val_accuracy: 0.8150\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2640 - accuracy: 0.8915 - val_loss: 0.4138 - val_accuracy: 0.8180\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2640 - accuracy: 0.8890 - val_loss: 0.4286 - val_accuracy: 0.8190\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2570 - accuracy: 0.8929 - val_loss: 0.4913 - val_accuracy: 0.8220\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2583 - accuracy: 0.8926 - val_loss: 0.4178 - val_accuracy: 0.8210\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2571 - accuracy: 0.8902 - val_loss: 0.3947 - val_accuracy: 0.8250\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2541 - accuracy: 0.8947 - val_loss: 0.4427 - val_accuracy: 0.8160\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2505 - accuracy: 0.8977 - val_loss: 0.4046 - val_accuracy: 0.8210\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2489 - accuracy: 0.8932 - val_loss: 0.4400 - val_accuracy: 0.8220\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2461 - accuracy: 0.9014 - val_loss: 0.4223 - val_accuracy: 0.8250\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2468 - accuracy: 0.8973 - val_loss: 0.4995 - val_accuracy: 0.8180\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2485 - accuracy: 0.8963 - val_loss: 0.4631 - val_accuracy: 0.8200\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2472 - accuracy: 0.8973 - val_loss: 0.4736 - val_accuracy: 0.8230\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2477 - accuracy: 0.8976 - val_loss: 0.4339 - val_accuracy: 0.8270\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2420 - accuracy: 0.8989 - val_loss: 0.4649 - val_accuracy: 0.8180\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2404 - accuracy: 0.9018 - val_loss: 0.4700 - val_accuracy: 0.8200\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2400 - accuracy: 0.8996 - val_loss: 0.4635 - val_accuracy: 0.8220\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2396 - accuracy: 0.8990 - val_loss: 0.4357 - val_accuracy: 0.8250\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2348 - accuracy: 0.9024 - val_loss: 0.6374 - val_accuracy: 0.8100\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2349 - accuracy: 0.9024 - val_loss: 0.4809 - val_accuracy: 0.8220\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2327 - accuracy: 0.9040 - val_loss: 0.5231 - val_accuracy: 0.8210\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2324 - accuracy: 0.9044 - val_loss: 0.4355 - val_accuracy: 0.8320\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2280 - accuracy: 0.9080 - val_loss: 0.5351 - val_accuracy: 0.8260\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2304 - accuracy: 0.9056 - val_loss: 0.5520 - val_accuracy: 0.8240\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2290 - accuracy: 0.9077 - val_loss: 0.5240 - val_accuracy: 0.8220\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2299 - accuracy: 0.9047 - val_loss: 0.4868 - val_accuracy: 0.8200\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2266 - accuracy: 0.9095 - val_loss: 0.5199 - val_accuracy: 0.8170\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2220 - accuracy: 0.9103 - val_loss: 0.5588 - val_accuracy: 0.8260\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2224 - accuracy: 0.9096 - val_loss: 0.5595 - val_accuracy: 0.8260\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2263 - accuracy: 0.9084 - val_loss: 0.5350 - val_accuracy: 0.8260\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2225 - accuracy: 0.9101 - val_loss: 0.5522 - val_accuracy: 0.8250\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2195 - accuracy: 0.9116 - val_loss: 0.5106 - val_accuracy: 0.8340\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2208 - accuracy: 0.9092 - val_loss: 0.5709 - val_accuracy: 0.8280\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2125 - accuracy: 0.9136 - val_loss: 0.5346 - val_accuracy: 0.8060\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([inputs_train,queries_train],answers_train,batch_size = 32,epochs = 100,\n",
    "                    validation_data = ([inputs_test,queries_test],answers_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "19505755",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating on the given test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8743b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8d6c8e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c2658ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7d34dac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "890711b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "90036891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.99979717\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a015d786",
   "metadata": {},
   "source": [
    "# Writing my own stories and questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5cb80c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3868bc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "251548d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6c5541df",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(),my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "94783c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6048b6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "10c8ff5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.8167605\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
